{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile util.py\n",
    "\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,GRU\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "\n",
    "def experiment(hps,dropout):\n",
    "    train_X, train_y  = get_data(hps.train_file,hps)\n",
    "    print('TRAIN:: ',train_X.shape,train_y.shape)\n",
    "\n",
    "\n",
    "    validate_X, validate_y  = get_data(hps.validate_file,hps)\n",
    "    print('VALIDATE:: ',validate_X.shape,validate_y.shape)    \n",
    "    \n",
    "    \n",
    "    # design network\n",
    "    if(hps.model_lstm):\n",
    "        if(hps.layered):\n",
    "            model = get_layered_lstm(hps,train_X,dropout)\n",
    "        else:\n",
    "            model = get_lstm(hps,train_X,dropout)\n",
    "    else:    \n",
    "        model = get_gru(hps,train_X,dropout)\n",
    "        \n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, \n",
    "                        epochs=hps.epochs, \n",
    "                        batch_size=hps.batch_size, \n",
    "                        validation_data=(validate_X, validate_y), \n",
    "                        verbose=2, \n",
    "                        shuffle=False)\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()   \n",
    "    \n",
    "    \n",
    "    test_X, test_y  = get_data(hps.test_file,hps)\n",
    "    print('TEST:: ',test_X.shape,test_y.shape)    \n",
    "    \n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = inv_y[:,0]\n",
    "    \n",
    "    return get_performace(inv_y,inv_yhat,test_X.shape[0],hps)\n",
    "\n",
    "\n",
    "\n",
    "def get_data(file_name,hps):\n",
    "    columns = ['start','user','session_id','gender','age','country','registered',\n",
    "               'prev_session_length','avg_session_length','session_length']\n",
    "    complete_files = glob.glob(file_name)\n",
    "    dataset = pd.concat((pd.read_csv(f,names=columns,sep='\\t') for f in complete_files))\n",
    "    \n",
    "    if(hps.filter_outliers):\n",
    "        df_perc = np.percentile(dataset.session_length, [hps.upper_limit])\n",
    "        dataset =  dataset[dataset.session_length < df_perc[0]]\n",
    "        dataset =  dataset[dataset.prev_session_length < df_perc[0]]\n",
    "\n",
    "    dataset = dataset.sort_values(by=['start'])  \n",
    "    \n",
    "    values = dataset.values\n",
    "    X = values[:,:-1]\n",
    "    y = values[:,-1]    \n",
    "    \n",
    "    #3D - samples,timesteps,features\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def get_layered_lstm(hps,train_X,dropout):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(hps.layer_dims, \n",
    "                   input_shape=(train_X.shape[1], \n",
    "                                train_X.shape[2]),\n",
    "                   return_sequences=True,\n",
    "                   dropout=dropout))\n",
    "    for i in range(hps.no_layers):\n",
    "        model.add(LSTM(hps.hidden_dim, \n",
    "                       dropout=dropout))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=hps.loss_func, \n",
    "                  optimizer=hps.optimizer)\n",
    "    return model\n",
    "\n",
    "def get_lstm(hps,train_X,dropout):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(hps.hidden_dim, \n",
    "                   input_shape=(train_X.shape[1], \n",
    "                                train_X.shape[2]),\n",
    "                   dropout=dropout))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=hps.loss_func, \n",
    "                  optimizer=hps.optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_gru(hps,train_X):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(hps.hidden_dim, \n",
    "                   input_shape=(train_X.shape[1], \n",
    "                                train_X.shape[2])))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=hps.loss_func, \n",
    "                  optimizer=hps.optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_performace(y,y_hat,samples,hps):\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(y, y_hat))\n",
    "#    print('Test RMSE: %.3f' % rmse)\n",
    "    \n",
    "    mae = mean_absolute_error(y, y_hat)\n",
    "#    print('Test MAE: %.3f' % mae)\n",
    "    \n",
    "    norm = mae/hps.baseline_mae\n",
    "#    print('Baseline Normalized MAE: %.3f' % norm)\n",
    "    \n",
    "    print('METRICS :: RMSE: {0} ; MAE: {1} ; Normalized MAE: {2}'.format(rmse,mae,norm))    \n",
    "#     pyplot.figure()\n",
    "#     pyplot.plot(y, label='actual')\n",
    "#     pyplot.plot(y_hat, label='pred')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()   \n",
    "    \n",
    "    return rmse,mae,norm\n",
    "\n",
    "\n",
    "    \n",
    "def get_data_1(file_name):\n",
    "    columns = ['start','user','session_id','gender','age','country','registered',\n",
    "               'prev_session_length','avg_session_length','session_length']\n",
    "    complete_files = glob.glob(file_name)\n",
    "    dataset = pd.concat((pd.read_csv(f,names=columns,sep='\\t') for f in complete_files))\n",
    "    \n",
    "    values = dataset.values\n",
    "    X = values[:,:-1]\n",
    "    y = values[:,-1]    \n",
    "    \n",
    "    #3D - samples,timesteps,features\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def get_sorted_data_1(file_name):\n",
    "    columns = ['start','user','session_id','gender','age','country','registered',\n",
    "               'prev_session_length','avg_session_length','session_length']\n",
    "    complete_files = glob.glob(file_name)\n",
    "    dataset = pd.concat((pd.read_csv(f,names=columns,sep='\\t') for f in complete_files))\n",
    "    dataset = dataset.sort_values(by=['start'])    \n",
    "    \n",
    "    values = dataset.values\n",
    "    X = values[:,:-1]\n",
    "    y = values[:,-1]    \n",
    "    \n",
    "    #3D - samples,timesteps,features\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
